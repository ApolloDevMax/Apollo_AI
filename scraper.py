import json
import os
import requests
import time
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ .env
load_dotenv()
SERPAPI_KEY = os.getenv("SERPAPI_KEY")

MEMORY_FILE = "memory.json"

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–∞–º—è—Ç–∏


def load_memory():
    if not os.path.exists(MEMORY_FILE):
        return {}
    with open(MEMORY_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# –§—É–Ω–∫—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–∞–º—è—Ç–∏


def save_memory(data):
    with open(MEMORY_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=4, ensure_ascii=False)

# –§—É–Ω–∫—Ü–∏—è –ø—Ä–æ–≤–µ—Ä–∫–∏, –¥–µ–ª–∞–ª—Å—è –ª–∏ —É–∂–µ —ç—Ç–æ—Ç –∑–∞–ø—Ä–æ—Å


def query_already_searched(query, memory):
    if "Internet_Search" in memory:
        for item in memory["Internet_Search"]:
            if item["query"].lower() == query.lower():
                return True  # –ó–∞–ø—Ä–æ—Å —É–∂–µ –≤—ã–ø–æ–ª–Ω—è–ª—Å—è
    return False

# –§—É–Ω–∫—Ü–∏—è –ø–æ–∏—Å–∫–∞ —á–µ—Ä–µ–∑ SerpAPI


def search_serpapi(query):
    url = "https://serpapi.com/search"
    params = {
        "q": query,
        "api_key": SERPAPI_KEY,
        "engine": "google",
        "num": 5  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    }
    try:
        response = requests.get(url, params=params)
        data = response.json()
        results = [result["snippet"] for result in data.get(
            "organic_results", []) if "snippet" in result]
        return results if results else ["–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö"]
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ: {e}")
        return ["–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö"]

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö


def run_scraper():
    memory = load_memory()

    # –°–ø–∏—Å–æ–∫ —Ç–µ–º –¥–ª—è –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
    queries = [
        "–Ω–æ–≤—ã–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–º –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–µ",
        "–±—É–¥—É—â–µ–µ Web3 –∏ –±–ª–æ–∫—á–µ–π–Ω–∞",
        "–∫–∞–∫ –∑–∞—Ä–∞–±–æ—Ç–∞—Ç—å –¥–µ–Ω—å–≥–∏ —Å –ø–æ–º–æ—â—å—é AI",
        "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏ –≤ –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å–∞",
        "—Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏ –∏—Ö –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª",
        "–Ω–æ–≤—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –≤ —Å—Ç–∞—Ä—Ç–∞–ø–∞—Ö",
        "—Å–∞–º–æ–æ–±—É—á–∞—é—â–∏–µ—Å—è —Å–∏—Å—Ç–µ–º—ã AI"
    ]

    new_data = []
    for query in queries:
        if query_already_searched(query, memory):
            print(f"‚è© –ü—Ä–æ–ø—É—Å–∫–∞–µ–º, —É–∂–µ –∏—Å–∫–∞–ª–∏: {query}")
            continue

        print(f"üîç –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {query}")
        results = search_serpapi(query)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ø–∞–º—è—Ç—å
        memory.setdefault("Internet_Search", []).append(
            {"query": query, "results": results})
        new_data.append((query, results))

        # –ñ–¥—ë–º 3 —Å–µ–∫—É–Ω–¥—ã, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –ø–æ API
        time.sleep(3)

    if new_data:
        save_memory(memory)
        print("\n‚úÖ –ù–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã!\n")
        for query, results in new_data:
            # –í—ã–≤–æ–¥–∏–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            print(f"üåê {query}: {results[:2]}...")


if __name__ == "__main__":
    run_scraper()
