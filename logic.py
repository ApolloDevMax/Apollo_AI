import spacy
import json
import networkx as nx
import numpy as np
from collections import defaultdict
from sentence_transformers import SentenceTransformer
import torch

# –ó–∞–≥—Ä—É–∂–∞–µ–º spaCy –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —è–∑—ã–∫–∞
nlp = spacy.load("ru_core_news_sm")

# –ó–∞–≥—Ä—É–∂–∞–µ–º BERT-–º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–º–∞–Ω—Ç–∏–∫–∏
semantic_sim = SentenceTransformer(
    "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")


class LogicEngine:
    def __init__(self, memory):
        self.memory = memory
        self.graph = nx.DiGraph()
        self.knowledge_base = defaultdict(dict)
        self.concept_similarity_threshold = 0.75  # –ü–æ—Ä–æ–≥ —Å—Ö–æ–∂–µ—Å—Ç–∏ –ø–æ–Ω—è—Ç–∏–π

    def analyze_knowledge(self):
        print("\n‚úÖ [DEBUG] –ó–∞–ø—É—â–µ–Ω –∞–Ω–∞–ª–∏–∑ –ø–∞–º—è—Ç–∏ –ê–ø–æ–ª–ª–æ–Ω–∞...")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏
        knowledge = self.memory.get_from_memory("ai_evolution")
        print(f"üü¢ [DEBUG] –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –ø–∞–º—è—Ç–∏: {knowledge}")

        if not knowledge:
            print("‚ö† –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞.")
            return

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ knowledge —Å–ª–æ–≤–∞—Ä–µ–º, –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Å—Ç—Ä–æ–∫—É
        if isinstance(knowledge, dict):
            knowledge = json.dumps(knowledge, ensure_ascii=False)

        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç —Å –ø–æ–º–æ—â—å—é spaCy
        doc = nlp(str(knowledge))
        key_terms = [
            token.lemma_ for token in doc if token.is_alpha and not token.is_stop]
        print(f"üîç [DEBUG] –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã: {key_terms}")

        # –í—ã—è–≤–ª—è–µ–º —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ç–µ—Ä–º–∏–Ω–∞–º–∏
        relations = self.extract_relations(doc)
        print(f"üìé [DEBUG] –û–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω—ã–µ —Å–≤—è–∑–∏: {relations}")

        # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π
        self.build_graph(relations)

        # –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–æ–±—ã—Ç–∏–π
        predictions = self.predict_outcomes()
        print(f"üîÆ [DEBUG] –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ–º—ã–µ —Å–æ–±—ã—Ç–∏—è: {predictions}")

        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º–∏
        concept_analysis = self.analyze_concept_similarity(relations)
        print(f"‚ö° [DEBUG] –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∫–æ–Ω—Ü–µ–ø—Ç–æ–≤: {concept_analysis}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∑–Ω–∞–Ω–∏—è –≤ –ø–∞–º—è—Ç—å
        self.memory.add_to_memory("knowledge_analysis", {
            "terms": key_terms,
            "relations": relations,
            "predictions": predictions,
            "concept_analysis": concept_analysis
        }, "long_term")

    def extract_relations(self, doc):
        """ –í—ã—è–≤–ª—è–µ—Ç —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Å–ª–æ–≤–∞–º–∏ –≤ —Ç–µ–∫—Å—Ç–µ, –∏—Å–ø–æ–ª—å–∑—É—è –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏. """
        relations = defaultdict(list)
        for token in doc:
            if token.dep_ in ("nsubj", "dobj", "amod"):
                relations[token.head.lemma_].append(token.lemma_)
        return relations

    def build_graph(self, relations):
        """ –°–æ–∑–¥–∞—ë—Ç –≥—Ä–∞—Ñ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –æ—Ç–Ω–æ—à–µ–Ω–∏–π. """
        for key, values in relations.items():
            for value in values:
                self.graph.add_edge(key, value)
        print("\nüï∏ [DEBUG] –ü–æ—Å—Ç—Ä–æ–µ–Ω –≥—Ä–∞—Ñ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö —Å–≤—è–∑–µ–π.")

    def predict_outcomes(self):
        """ –ü—Ä–æ–≥–Ω–æ–∑–∏—Ä—É–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–≤—è–∑–µ–π –≤ –≥—Ä–∞—Ñ–µ. """
        predictions = {}
        for node in self.graph.nodes:
            neighbors = list(self.graph.successors(node))
            if "–ø—Ä–æ–±–ª–µ–º–∞" in neighbors:
                predictions[node] = f"üö® –í–æ–∑–º–æ–∂–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞ —Å '{node}'"
            elif "—Ä–µ—à–µ–Ω–∏–µ" in neighbors:
                predictions[node] = f"‚úÖ –í–µ—Ä–æ—è—Ç–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ —Å–≤—è–∑–∞–Ω–æ —Å '{node}'"
        return predictions

    def analyze_concept_similarity(self, relations):
        """ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–∂–µ—Å—Ç—å –ø–æ–Ω—è—Ç–∏–π –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è —Å–∫—Ä—ã—Ç—ã—Ö –∑–∞–∫–æ–Ω–æ–º–µ—Ä–Ω–æ—Å—Ç–µ–π. """
        concept_pairs = []
        concepts = list(relations.keys())

        for i in range(len(concepts)):
            for j in range(i + 1, len(concepts)):
                vec1 = semantic_sim.encode(concepts[i], convert_to_tensor=True)
                vec2 = semantic_sim.encode(concepts[j], convert_to_tensor=True)
                similarity = torch.cosine_similarity(vec1, vec2, dim=0).item()
                if similarity > self.concept_similarity_threshold:
                    concept_pairs.append(
                        (concepts[i], concepts[j], round(similarity, 3)))
        return concept_pairs


# ‚úÖ –ì–ê–†–ê–ù–¢–ò–†–û–í–ê–ù–ù–´–ô –ó–ê–ü–£–°–ö –ö–û–î–ê
if __name__ == "__main__":
    print("üöÄ [DEBUG] –ó–∞–ø—É—Å–∫ logic.py...")
    from memory import Memory  # –£–±–µ–¥–∏—Å—å, —á—Ç–æ memory.py –≤ —Ç–æ–π –∂–µ –ø–∞–ø–∫–µ

    print("üü¢ [DEBUG] –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç –ø–∞–º—è—Ç–∏...")
    memory = Memory()

    print("üü¢ [DEBUG] –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–º—è—Ç—å...")
    memory.add_to_memory("ai_evolution",
                         "–ê–ø–æ–ª–ª–æ–Ω ‚Äì —ç—Ç–æ –ø–µ—Ä–≤—ã–π —à–∞–≥ –∫ —Å–æ–∑–¥–∞–Ω–∏—é AGI. –ï–≥–æ —Ü–µ–ª—å ‚Äì —Å—Ç–∞—Ç—å –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–∏—Å—Ç–µ–º–æ–π, "
                         "—Å–ø–æ—Å–æ–±–Ω–æ–π –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥—ã –∏ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å—Å—è –∫ –Ω–æ–≤—ã–º —É—Å–ª–æ–≤–∏—è–º. "
                         "–°–µ–π—á–∞—Å –º—ã –æ–±—É—á–∞–µ–º –µ–≥–æ –ø–æ–Ω–∏–º–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç, –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏. "
                         "–í –±—É–¥—É—â–µ–º –æ–Ω –±—É–¥–µ—Ç —Å–ø–æ—Å–æ–±–µ–Ω –∞–≤—Ç–æ–Ω–æ–º–Ω–æ —Ä–∞–±–æ—Ç–∞—Ç—å –≤ –æ–±–ª–∞–∫–µ –∏ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏.",
                         "long_term"
                         )

    print("üü¢ [DEBUG] –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –∑–Ω–∞–Ω–∏–π...")
    logic_engine = LogicEngine(memory)
    logic_engine.analyze_knowledge()

    print("‚úÖ [DEBUG] –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω!")
